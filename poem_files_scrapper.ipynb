{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abecedarian', 'acrostic', 'alexandrine', 'allegory', 'anacreontic', 'anagram', 'anaphora', 'arabian-sonnet', 'ars-poetica', 'aubade', 'balassi-stanza', 'ballad', 'ballade', 'beymorlin-sonnet', 'bio', 'blank-verse', 'blues-poem', 'blues-sonnet', 'bop', 'bref-double', 'brisbane-sonnet', 'bucolic', 'burlesque', 'burns-stanza', 'busta-sonetto', 'cacophony', 'canzone', 'canzonetta', 'carol', 'carpe-diems', 'cascade', 'catena-rondo', 'cavatina', 'cento', 'chain-verse', 'chance-operations', 'choka', 'cinquain', 'clerihew', 'collins-sestet', 'conceit', 'couplet', 'curtal-sonnet', 'dactyl', 'decastich', 'didactic-poetry', 'dirge', 'divino-sonetto', 'dizain', 'doggerel', 'double-dactyl', 'dramatic-monologue', 'echo-verse', 'eclogue', 'ekphrastic', 'elegy', 'envoi-or-envoy', 'epic', 'epigram', 'epistle', 'epistrophe', 'epitaph', 'epithalamion', 'found-poem', 'fourteener', 'free-verse', 'ghazal', 'glosa', 'gnomic-verse', 'haiku', 'heroic-couplet', 'horatian-ode', 'hymn', 'iambic-pentameter', 'idyll-or-idyl', 'imagery', 'irregular-ode', 'italian-sonnet', 'kennings', 'kyrielle', 'lament', 'landays', 'lay', 'light-verse', 'limerick', 'lyric', 'madrigal', 'mock-epic', 'monoku', 'narrative', 'nonet', 'occasional-poem', 'octave', 'ode', 'ottava-rima', 'oulipo', 'palindrome-or-mirror-poetry', 'palinode', 'panegyric', 'pantoum', 'pastoral', 'pindaric-ode', 'prose-poem', 'qasida', 'quatern', 'quatrain', 'refrain', 'renga', 'rhyme-royal-or-rime-royale', 'rictameter', 'riddle', 'rispetto', 'rondeau', 'rondel-or-roundel', 'sapphic', 'senryu', 'sestet', 'sestina', 'shadorma', 'shi', 'sijo', 'slam', 'somonka', 'sonnet', 'spenserian-stanza', 'stanza', 'syllabic-verse', 'tanka', 'tercet', 'terza-rima', 'tetractys', 'the-blitz', 'triolet', 'triversen', 'tyburn', 'verse', 'verse-paragraph', 'villanelle']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_folders(directory):\n",
    "    try:\n",
    "        # Get a list of all files and directories in the specified directory\n",
    "        items = os.listdir(directory)\n",
    "        \n",
    "        # Filter out only the directories\n",
    "        folders = [item for item in items if os.path.isdir(os.path.join(directory, item))]\n",
    "        \n",
    "        return folders\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Example usage\n",
    "directory = 'forms'\n",
    "folders = list_folders(directory)\n",
    "print(folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def compile_text_files(directory, output_file):\n",
    "    try:\n",
    "        # Open the output file in write mode\n",
    "        with open(output_file, 'w') as outfile:\n",
    "            # Get a list of all directories in the specified directory\n",
    "            for folder in os.listdir(directory):\n",
    "                folder_path = os.path.join(directory, folder)\n",
    "                if os.path.isdir(folder_path):\n",
    "                    # Get a list of all text files in the current folder\n",
    "                    for file_name in os.listdir(folder_path):\n",
    "                        if file_name.endswith('.txt'):\n",
    "                            file_path = os.path.join(folder_path, file_name)\n",
    "                            # Open and read each text file, then write its contents to the output file\n",
    "                            with open(file_path, 'r') as infile:\n",
    "                                contents = infile.read()\n",
    "                                outfile.write(contents + '\\n')\n",
    "        return \"Files compiled successfully.\"\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Example usage\n",
    "directory = 'forms'\n",
    "output_file = 'compiled_output.txt'\n",
    "result = compile_text_files(directory, output_file)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m words\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import re\n",
    "\n",
    "# Download the word list if not already downloaded\n",
    "nltk.download('words')\n",
    "\n",
    "def clean_text_file(input_file, output_file):\n",
    "    # Get a set of English words\n",
    "    english_words = set(words.words())\n",
    "    \n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            # Split the line into words\n",
    "            word_list = re.findall(r'\\b\\w+\\b', line)\n",
    "            # Filter out non-English words\n",
    "            cleaned_words = [word for word in word_list if word.lower() in english_words]\n",
    "            # Write the cleaned words to the output file\n",
    "            outfile.write(' '.join(cleaned_words) + '\\n')\n",
    "\n",
    "# Example usage\n",
    "input_file = 'poems_dataset.txt'  # Replace with your input file path\n",
    "output_file = 'cleaned_output.txt'  # Replace with your desired output file path\n",
    "clean_text_file(input_file, output_file)\n",
    "print(\"File cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m words\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import re\n",
    "\n",
    "# Download the word list if not already downloaded\n",
    "nltk.download('words')\n",
    "\n",
    "def clean_text_line_by_line(input_file, output_file):\n",
    "    # Get a set of English words\n",
    "    english_words = set(words.words())\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            # Split the line into words\n",
    "            word_list = re.findall(r'\\b\\w+\\b', line)\n",
    "            # Filter out non-English words\n",
    "            cleaned_words = [word for word in word_list if word.lower() in english_words]\n",
    "            # Write the cleaned words to the output file, preserving line endings\n",
    "            outfile.write(' '.join(cleaned_words) + '\\n')\n",
    "\n",
    "# Example usage\n",
    "file_path = '/content/drive/MyDrive/poems_dataset.txt'\n",
    "output_file_path = '/content/drive/MyDrive/cleaned_poems_dataset.txt'\n",
    "\n",
    "# Clean the text line by line and preserve line endings\n",
    "clean_text_line_by_line(file_path, output_file_path)\n",
    "\n",
    "print(\"File cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "butterfly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
